{"cells":[{"cell_type":"markdown","id":"e21c4548","metadata":{"id":"e21c4548"},"source":["# 文本数据处理\n","\n","**清洗 → tokenize → vocab → corpus**"]},{"cell_type":"markdown","id":"9b7197cb","metadata":{"id":"9b7197cb"},"source":["## 1. 读取并清洗文本"]},{"cell_type":"code","execution_count":1,"id":"9c4f132b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9c4f132b","executionInfo":{"status":"ok","timestamp":1769342162261,"user_tz":-480,"elapsed":43,"user":{"displayName":"Allen Wei","userId":"00558309039811553346"}},"outputId":"45e52040-0b80-46cd-e3f3-16448b3b33c3"},"outputs":[{"output_type":"stream","name":"stdout","text":["6779\n","the project gutenberg ebook of the great gatsby\n"]}],"source":["import collections\n","import re\n","\n","file_path = 'novel.txt'\n","\n","def read_txt_file(file_path):\n","    with open(file_path, 'r') as f:\n","        lines = f.readlines()\n","    cleaned_lines = [\n","        re.sub('[^A-Za-z]+', ' ', line).strip().lower()\n","        for line in lines\n","    ]\n","    return cleaned_lines\n","\n","lines = read_txt_file(file_path)\n","print(len(lines))\n","print(lines[0])"]},{"cell_type":"markdown","id":"c0b85db2","metadata":{"id":"c0b85db2"},"source":["## 2. Tokenize"]},{"cell_type":"code","execution_count":2,"id":"bbc66d84","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bbc66d84","executionInfo":{"status":"ok","timestamp":1769342162285,"user_tz":-480,"elapsed":15,"user":{"displayName":"Allen Wei","userId":"00558309039811553346"}},"outputId":"993d02d7-664f-4046-8787-27d94c1b1ce4"},"outputs":[{"output_type":"stream","name":"stdout","text":["['the', 'project', 'gutenberg', 'ebook', 'of', 'the', 'great', 'gatsby']\n"]}],"source":["def tokenize(lines, token='word'):\n","    if token == 'word':\n","        return [line.split() for line in lines]\n","    elif token == 'char':\n","        return [list(line) for line in lines]\n","    else:\n","        raise ValueError(token)\n","\n","tokens = tokenize(lines, 'word')\n","print(tokens[0])"]},{"cell_type":"markdown","id":"e6e43820","metadata":{"id":"e6e43820"},"source":["## 3. 构建词表 Vocab"]},{"cell_type":"code","execution_count":6,"id":"68fa467a","metadata":{"id":"68fa467a","executionInfo":{"status":"ok","timestamp":1769342324579,"user_tz":-480,"elapsed":3,"user":{"displayName":"Allen Wei","userId":"00558309039811553346"}}},"outputs":[],"source":["import collections\n","\n","def count_corpus(corpus):\n","    \"\"\"\n","    统计语料中每个 token 出现的次数\n","    tokens:\n","        - 可以是 ['a', 'b', 'c']\n","        - 也可以是 [['a','b'], ['c','d']]\n","    返回：\n","        Counter({'a': 3, 'b': 2, ...})\n","    \"\"\"\n","    all_tokens = []\n","    for line in corpus:          # 一行一行取\n","      for token in line.split():       # 行里一个个 token 取\n","          all_tokens.append(token)\n","\n","\n","    return collections.Counter(all_tokens)\n","\n","class Vocab:\n","    def __init__(self, tokens=None):\n","        \"\"\"\n","        构建词表\n","        tokens: token 列表（可以是一维或二维）\n","        \"\"\"\n","        if tokens is None:\n","            tokens = []\n","\n","        # 1. 统计词频\n","        counter = count_corpus(tokens)\n","\n","        # 2. 初始化特殊符号\n","        self.idx_to_token = ['<unk>', '<bos>', '<eos>']\n","        self.token_to_idx = {\n","            '<unk>': 0,\n","            '<bos>': 1,\n","            '<eos>': 2\n","        }\n","\n","        # 3. 按频率从高到低加入普通 token\n","        for token, freq in counter.most_common():\n","            if token not in self.token_to_idx:\n","                self.idx_to_token.append(token)\n","                self.token_to_idx[token] = len(self.idx_to_token) - 1\n","\n","    def __len__(self):\n","      return len(self.idx_to_token)\n","\n","    def __getitem__(self, tokens):\n","      # 单个 token\n","      if not isinstance(tokens, (list, tuple)):\n","          return self.token_to_idx.get(tokens, self.token_to_idx['<unk>'])\n","\n","      # token 列表\n","      indices = []\n","      for token in tokens:\n","          indices.append(self[token])\n","      return indices\n","\n","\n","    def print_vocab(self, n=10):\n","      print(\"===== Vocabulary Preview =====\")\n","      print(\"index -> token\")\n","      for i in range(min(n, len(self.idx_to_token))):\n","          print(f\"{i:>3} -> {self.idx_to_token[i]}\")\n"]},{"cell_type":"markdown","id":"3b384ae5","metadata":{"id":"3b384ae5"},"source":["## 4. 构建字符级 corpus"]},{"cell_type":"code","execution_count":8,"id":"ba0ba1bf","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ba0ba1bf","executionInfo":{"status":"ok","timestamp":1769342334763,"user_tz":-480,"elapsed":8,"user":{"displayName":"Allen Wei","userId":"00558309039811553346"}},"outputId":"b48aa5d4-336c-473a-fe1e-883cab512741"},"outputs":[{"output_type":"stream","name":"stdout","text":["===== Vocabulary Preview =====\n","index -> token\n","  0 -> <unk>\n","  1 -> <bos>\n","  2 -> <eos>\n","  3 -> the\n","  4 -> and\n","  5 -> a\n","  6 -> i\n","  7 -> of\n","  8 -> to\n","  9 -> in\n"," 10 -> he\n"," 11 -> was\n"," 12 -> that\n"," 13 -> it\n"," 14 -> you\n"," 15 -> his\n"," 16 -> s\n"," 17 -> with\n"," 18 -> at\n"," 19 -> t\n"," 20 -> she\n"," 21 -> her\n"," 22 -> had\n"," 23 -> on\n"," 24 -> for\n"," 25 -> me\n"," 26 -> as\n"," 27 -> him\n"," 28 -> gatsby\n"," 29 -> but\n"," 30 -> from\n"," 31 -> my\n"," 32 -> we\n"," 33 -> all\n"," 34 -> said\n"," 35 -> there\n"," 36 -> out\n"," 37 -> this\n"," 38 -> up\n"," 39 -> an\n"," 40 -> tom\n"," 41 -> daisy\n"," 42 -> or\n"," 43 -> were\n"," 44 -> they\n"," 45 -> if\n"," 46 -> into\n"," 47 -> about\n"," 48 -> one\n"," 49 -> by\n"," 50 -> when\n"," 51 -> what\n"," 52 -> have\n"," 53 -> then\n"," 54 -> over\n"," 55 -> be\n"," 56 -> so\n"," 57 -> is\n"," 58 -> like\n"," 59 -> down\n"," 60 -> who\n"," 61 -> man\n"," 62 -> no\n"," 63 -> back\n"," 64 -> came\n"," 65 -> been\n"," 66 -> any\n"," 67 -> d\n"," 68 -> some\n"," 69 -> do\n"," 70 -> just\n"," 71 -> little\n"," 72 -> not\n"," 73 -> now\n"," 74 -> know\n"," 75 -> gutenberg\n"," 76 -> don\n"," 77 -> house\n"," 78 -> before\n"," 79 -> went\n"," 80 -> project\n"," 81 -> after\n"," 82 -> eyes\n"," 83 -> old\n"," 84 -> didn\n"," 85 -> come\n"," 86 -> looked\n"," 87 -> got\n"," 88 -> mr\n"," 89 -> see\n"," 90 -> time\n"," 91 -> other\n"," 92 -> them\n"," 93 -> away\n"," 94 -> your\n"," 95 -> way\n"," 96 -> ll\n"," 97 -> wilson\n"," 98 -> m\n"," 99 -> can\n","now -> 73\n","unknown -> 0\n","sentence -> [1, 1035, 61, 2]\n"]}],"source":["vocab = Vocab(lines)\n","\n","vocab.print_vocab(n=100)\n","\n","print(\"now ->\", vocab['now'])\n","print(\"unknown ->\", vocab['xyz'])\n","print(\"sentence ->\", vocab[['<bos>', 'interest', 'man', '<eos>']])"]}],"metadata":{"colab":{"provenance":[]},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":5}