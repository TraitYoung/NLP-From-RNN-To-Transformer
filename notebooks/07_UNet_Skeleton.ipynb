{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0acd516",
   "metadata": {
    "vscode": {
     "languageId": "ini"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformer_core import CrossAttention # 假设你把上节课的代码存为了这个名字，或者直接复制过来\n",
    "\n",
    "class ResNetBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    基础的卷积模块，用于处理图像特征。\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, padding=1)\n",
    "        self.act = nn.SiLU() # Diffusion 常用激活函数\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.act(self.conv1(x))\n",
    "        return self.conv2(h) + x # 残差连接 (防止梯度消失)\n",
    "\n",
    "class SpatialTransformer(nn.Module):\n",
    "    \"\"\"\n",
    "    【关键模块】：将文本信息注入图像的地方。\n",
    "    包含：Self-Attention (图像自己整理逻辑) + Cross-Attention (听文本指挥)\n",
    "    \"\"\"\n",
    "    def __init__(self, channels, context_dim):\n",
    "        super().__init__()\n",
    "        self.norm = nn.GroupNorm(32, channels)\n",
    "        # 1x1 卷积把 (B, C, H, W) 变成 (B, C, H*W) 以便 Transformer 处理\n",
    "        self.proj_in = nn.Conv2d(channels, channels, kernel_size=1)\n",
    "        \n",
    "        # 你的 CrossAttention 代码在这里被调用！\n",
    "        self.transformer = CrossAttention(d_model=channels, d_context=context_dim, n_head=4)\n",
    "        \n",
    "        self.proj_out = nn.Conv2d(channels, channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x, context):\n",
    "        b, c, h, w = x.shape\n",
    "        x_in = x\n",
    "        \n",
    "        # 1. 变形: Image -> Sequence\n",
    "        x = self.norm(x)\n",
    "        x = self.proj_in(x)\n",
    "        x = x.flatten(2).transpose(1, 2) # (B, H*W, C)\n",
    "        \n",
    "        # 2. Attention: 图像特征 x 去查询 文本特征 context\n",
    "        x = self.transformer(x, context)\n",
    "        \n",
    "        # 3. 还原: Sequence -> Image\n",
    "        x = x.transpose(1, 2).reshape(b, c, h, w)\n",
    "        return self.proj_out(x) + x_in\n",
    "\n",
    "class SimpleUNet(nn.Module):\n",
    "    \"\"\"\n",
    "    极简版 U-Net 架构，展示核心逻辑。\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels=320, context_dim=768):\n",
    "        super().__init__()\n",
    "        # 1. 编码器 (下采样)\n",
    "        self.down_blocks = nn.ModuleList([\n",
    "            ResNetBlock(in_channels, in_channels),\n",
    "            ResNetBlock(in_channels, in_channels)\n",
    "        ])\n",
    "        \n",
    "        # 2. 中间层 (最关键的地方，通常在这里加 Attention)\n",
    "        self.mid_block1 = ResNetBlock(in_channels, in_channels)\n",
    "        self.mid_attn = SpatialTransformer(in_channels, context_dim) # <-- 文本在这里注入\n",
    "        self.mid_block2 = ResNetBlock(in_channels, in_channels)\n",
    "        \n",
    "        # 3. 解码器 (上采样)\n",
    "        self.up_blocks = nn.ModuleList([\n",
    "            ResNetBlock(in_channels, in_channels),\n",
    "            ResNetBlock(in_channels, in_channels)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, context):\n",
    "        # x: 噪声图像, context: 文本提示词向量\n",
    "        \n",
    "        # Down\n",
    "        for block in self.down_blocks:\n",
    "            x = block(x)\n",
    "            \n",
    "        # Middle (文本控制发生在这里)\n",
    "        x = self.mid_block1(x)\n",
    "        x = self.mid_attn(x, context) # Cross-Attention!\n",
    "        x = self.mid_block2(x)\n",
    "        \n",
    "        # Up\n",
    "        for block in self.up_blocks:\n",
    "            x = block(x)\n",
    "            \n",
    "        return x\n",
    "\n",
    "# --- 测试代码 ---\n",
    "if __name__ == \"__main__\":\n",
    "    # 模拟输入\n",
    "    dummy_img = torch.randn(1, 320, 32, 32) # Batch, Channel, H, W\n",
    "    dummy_txt = torch.randn(1, 77, 768)     # Batch, Token, Dim (CLIP output)\n",
    "    \n",
    "    model = SimpleUNet()\n",
    "    output = model(dummy_img, dummy_txt)\n",
    "    \n",
    "    print(f\"Input Image: {dummy_img.shape}\")\n",
    "    print(f\"Output Image: {output.shape}\")\n",
    "    print(\"U-Net structure verified. Text injection successful.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
