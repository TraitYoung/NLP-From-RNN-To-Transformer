{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0acd516",
   "metadata": {
    "vscode": {
     "languageId": "ini"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from Transformer_Core import CrossAttention \n",
    "\n",
    "class ResNetBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    基础的卷积模块，用于处理图像特征。\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, padding=1)\n",
    "        self.act = nn.SiLU() # Diffusion 常用激活函数\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.act(self.conv1(x))\n",
    "        return self.conv2(h) + x # 残差连接\n",
    "\n",
    "class SpatialTransformer(nn.Module):\n",
    "    \"\"\"\n",
    "    【关键模块】：将文本信息注入图像的地方。\n",
    "    \"\"\"\n",
    "    def __init__(self, channels, context_dim):\n",
    "        super().__init__()\n",
    "        # GroupNorm 需要通道数能被 32 整除，所以 channels 至少要是 32，通常是 64, 128, 320...\n",
    "        self.norm = nn.GroupNorm(32, channels)\n",
    "        self.proj_in = nn.Conv2d(channels, channels, kernel_size=1)\n",
    "        self.transformer = CrossAttention(d_model=channels, d_context=context_dim, n_head=4)\n",
    "        self.proj_out = nn.Conv2d(channels, channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x, context):\n",
    "        b, c, h, w = x.shape\n",
    "        x_in = x\n",
    "        x = self.norm(x)\n",
    "        x = self.proj_in(x)\n",
    "        x = x.flatten(2).transpose(1, 2) \n",
    "        x = self.transformer(x, context)\n",
    "        x = x.transpose(1, 2).reshape(b, c, h, w)\n",
    "        return self.proj_out(x) + x_in\n",
    "\n",
    "class SimpleUNet(nn.Module):\n",
    "    \"\"\"\n",
    "    极简版 U-Net 架构 (已修复通道数问题)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels=3, model_channels=64, context_dim=768):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 1. 【新增】入口层：把 3 通道图片变成 64 通道特征\n",
    "        # 这解决了 \"3 不能被 32 整除\" 的报错\n",
    "        self.init_conv = nn.Conv2d(in_channels, model_channels, kernel_size=3, padding=1)\n",
    "        \n",
    "        # 这里的通道数全部改成 model_channels (64)\n",
    "        self.down_blocks = nn.ModuleList([\n",
    "            ResNetBlock(model_channels, model_channels),\n",
    "            ResNetBlock(model_channels, model_channels)\n",
    "        ])\n",
    "        \n",
    "        # 中间层\n",
    "        self.mid_block1 = ResNetBlock(model_channels, model_channels)\n",
    "        self.mid_attn = SpatialTransformer(model_channels, context_dim) \n",
    "        self.mid_block2 = ResNetBlock(model_channels, model_channels)\n",
    "        \n",
    "        # 上采样\n",
    "        self.up_blocks = nn.ModuleList([\n",
    "            ResNetBlock(model_channels, model_channels),\n",
    "            ResNetBlock(model_channels, model_channels)\n",
    "        ])\n",
    "\n",
    "        # 【新增】出口层：把 64 通道特征变回 3 通道图片 (为了预测噪声)\n",
    "        self.out_conv = nn.Conv2d(model_channels, in_channels, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x, context):\n",
    "        # x: (Batch, 3, 64, 64)\n",
    "        \n",
    "        # 先升维：(Batch, 64, 64, 64)\n",
    "        x = self.init_conv(x)\n",
    "        \n",
    "        # Down\n",
    "        for block in self.down_blocks:\n",
    "            x = block(x)\n",
    "            \n",
    "        # Middle\n",
    "        x = self.mid_block1(x)\n",
    "        x = self.mid_attn(x, context)\n",
    "        x = self.mid_block2(x)\n",
    "        \n",
    "        # Up\n",
    "        for block in self.up_blocks:\n",
    "            x = block(x)\n",
    "            \n",
    "        # 后降维：(Batch, 3, 64, 64)\n",
    "        return self.out_conv(x)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
