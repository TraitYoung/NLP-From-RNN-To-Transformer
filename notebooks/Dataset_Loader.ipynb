{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265960a1",
   "metadata": {
    "vscode": {
     "languageId": "ini"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "\n",
    "class MedicalImageDataset(Dataset):\n",
    "    \"\"\"\n",
    "    æ¯•è®¾ä¸“ç”¨æ•°æ®åŠ è½½å™¨ã€‚\n",
    "    è¯»å–æ–‡ä»¶å¤¹é‡Œçš„å›¾ç‰‡ï¼Œå¹¶æŠŠå®ƒä»¬å˜æˆ Tensor å–‚ç»™æ¨¡å‹ã€‚\n",
    "    \"\"\"\n",
    "    def __init__(self, img_dir, image_size=64):\n",
    "        # 1. æ‰¾åˆ°æ–‡ä»¶å¤¹é‡Œæ‰€æœ‰çš„å›¾ç‰‡ (jpg, png, jpeg)\n",
    "        self.image_paths = []\n",
    "        for ext in ['*.jpg', '*.png', '*.jpeg']:\n",
    "            # é€’å½’æŸ¥æ‰¾\n",
    "            self.image_paths.extend(glob.glob(os.path.join(img_dir, '**', ext), recursive=True))\n",
    "            \n",
    "        print(f\"ğŸ” Found {len(self.image_paths)} images in {img_dir}\")\n",
    "        \n",
    "        # 2. å®šä¹‰å›¾ç‰‡é¢„å¤„ç† (æ¯•è®¾å¿…é¡»æ­¥éª¤)\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((image_size, image_size)), # ç»Ÿä¸€å¤§å°\n",
    "            transforms.ToTensor(),                       # å˜å¼ é‡ (0~1)\n",
    "            transforms.Normalize([0.5], [0.5])           # å½’ä¸€åŒ–åˆ° (-1~1)ï¼Œè¿™æ˜¯ Diffusion çš„æ ‡å‡†\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # è¯»å–å›¾ç‰‡\n",
    "        img_path = self.image_paths[idx]\n",
    "        try:\n",
    "            image = Image.open(img_path).convert(\"RGB\") # å¼ºè½¬RGBï¼Œé˜²æ­¢ç°åº¦å›¾æŠ¥é”™\n",
    "            return self.transform(image)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {img_path}: {e}\")\n",
    "            return torch.zeros(3, 64, 64) # åå›¾è¿”å›å…¨é»‘ï¼Œé˜²æ­¢ç¨‹åºå´©æºƒ\n",
    "\n",
    "# --- æµ‹è¯•ä»£ç  ---\n",
    "if __name__ == \"__main__\":\n",
    "    # é™›ä¸‹ï¼Œä¸ºäº†æµ‹è¯•ï¼Œè¯·åœ¨ä½ ç”µè„‘çš„ data æ–‡ä»¶å¤¹é‡Œéšä¾¿æ”¾å‡ å¼  jpg å›¾ç‰‡ï¼\n",
    "    # æ¯”å¦‚: ../data/demo_images/\n",
    "    dataset = MedicalImageDataset(img_dir=\"../data\", image_size=64)\n",
    "    if len(dataset) > 0:\n",
    "        img = dataset[0]\n",
    "        print(f\"Image Shape: {img.shape}\") # åº”è¯¥æ˜¯ (3, 64, 64)\n",
    "        print(f\"Value Range: [{img.min():.2f}, {img.max():.2f}]\") # åº”è¯¥æ˜¯ [-1, 1]\n",
    "    else:\n",
    "        print(\"âš ï¸ æ²¡æ‰¾åˆ°å›¾ç‰‡ï¼Œè¯·åœ¨ data æ–‡ä»¶å¤¹é‡Œæ”¾ç‚¹å›¾æµ‹è¯•ï¼\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
